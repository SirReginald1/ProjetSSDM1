---
title: "Resultat test n et p"
date: last-modified
format: 
  html:
    fig-format: svg
    embed-resources: true
toc: true
toc-title: "Summary"
toc-location: left
toc-depth: 3
lightbox: true
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(warning = FALSE, echo = FALSE, fig.pos="H", message = FALSE)
source("Scripts/functions.R")
if(!require("ggplot2")){install.packages("ggplot2")}
if(!require("kableExtra")){install.packages("kableExtra")}
if(!require("ggpubr")){install.packages("ggpubr")}
if(!require("jsonlite")){install.packages("jsonlite")}
if(!require("corrplot")){install.packages("corrplot")}
if(!require("e1071")){install.packages("e1071")}
if(!require("xgboost")){install.packages("xgboost")}
```



- Pour que ce fichier fonctionne sens aucune modification des scriptes, un fichier **"OldData"** doit être présent dans le répertoire de travail. Et doit contenir les fichiers suivent :

    + df_newas10_train.rds

    + df_newas20_train.rds

    + df_newas30_train.rds
    
    + df_newas50_train.rds
    
    + df_newas100_train.rds
    
    + df_newas200_train.rds
    
    + df_newas300_train.rds
    
    + df_newas500_train.rds
    
    + df_preproc_test.rds
    
    + df_preproc_train.rds


Ce script construit des sous-jeux de données test équivalent à des jeux de données train présent dans le répertoire donné pour limiter l'utilisation de la mémoire pour les ordinateurs moins puissent.    
```{r, echo=TRUE}
input_path = "OldData"
output_path = "OldOutput"
test_data_path = "OldData"
source("Scripts/build_test_sets.R")
```

# Test n et p

```{r, include=FALSE}
source("Scripts/test_all_np.R") # WARNING WILL REPLACE CURENT RESULTS
```


## Donnée original 69 classes

```{r}
rf_Oldres = readRDS("OldDataOutput/randomForest_rf/randomForest_rf_res.rds")
svm_Oldres = readRDS("OldDataOutput/e1071_svm/e1071_svm_res.rds")
xgb_Oldres = readRDS("OldDataOutput/xgboost_xgboost/xgboost_xgboost_res.rds")
```



```{r, fig.width=15, fig.height=16, fig.cap="Figure 1: Résultat des temps de calcul et de l'accuracy pour les jeux d'entraînement et de test en fonction du nombre d'observations et du nombre de variables pour chaque modèle pour les données originales non équilibré (69) classes."}
ggarrange(plot_res_np(rf_Oldres, "acc_train"), 
          plot_res_np(rf_Oldres, "acc_test"),
          plot_res_np(rf_Oldres, "time"),
          plot_res_np(svm_Oldres, "acc_train"), 
          plot_res_np(svm_Oldres, "acc_test"),
          plot_res_np(svm_Oldres, "time"),
          plot_res_np(xgb_Oldres, "acc_train"), 
          plot_res_np(xgb_Oldres, "acc_test"),
          plot_res_np(xgb_Oldres, "time"),
          labels = c("RF", "", "","SVM", "", "","XGB", "", ""),
          ncol = 3, nrow = 4)
```

```{r}
temp = data.frame("Random forest" = get_max_results(rf_Oldres)[2:3],
                  "SVM" = get_max_results(svm_Oldres)[2:3],
                  "XgBoost" = get_max_results(xgb_Oldres)[2:3]) 
rownames(temp) = c("Test accuracy", "Temp de calcul en seconds")
kbl(round(temp, 2), align = "c", caption = "Table 1: Résultats des modèles avec les données originales pour n et p max calculé.")
```


### Random Forest

- Language: R
- Package: randomForest

Le random forest est de loin le modèle qui prend le plus de temps a calculer. Il est probable que cela soit dû au fait que le modèle calcule la pureté des nœuds pour les "split" de toutes les variables restent. Ceci est exacerbé par le fait que pour des variables continues il doit calculer le "split" pour chaque valeur existante de la variable présente dans le jeu de données.

Le random forest semble être le modèle qui a sont accuracy le mois affecté par un nombre de variables réduits, mais de ce fait plus sensible au nombre d'observations.

On remarquera que le random forest classifie toujours parfaitement notre jeu de donnée d'entraînement. Il est probable que ceci soit impacté par le découpage en nœud précis fait avec les données continues.

#### Liste des paramètres utilisés

- **mtry** = sqrt(p):

- **ntree:** 500

#### Classification par classe random forest

Les classes sur l'axe des abscisses sont ordonnées en fonction de leur prévalence dans le jeu de donnée entier de manière descendante.

```{r, fig.width=15, fig.height=7, fig.cap="Figure 2: Classification par classe du modèle random forest pour n et p max calculé."}
plot_class(rf_Oldres[[length(rf_Oldres)]][["results"]][["pred_labs"]],
           rf_Oldres[[length(rf_Oldres)]][["results"]][["test_labs"]])
```




### SVM

- Language: R
- Package: e1071

Le svm semble aussi être sensible au nombre de variables utilisées. Cependant, il converge plus vite que le réseau de neurones.

Nous sommes en train de comprendre les mathématiques utilisées pas le SVM pour pouvoirs expliquer sa performance.

La baisse de l'accuracy pour les modèles avec un petit nombre de variables peut s'expliquer par la difficulté de tracer un hyperplan pour bien séparer les données plus le nombre d'observations est élevé. Mais plus le nombre de variables plus le nombre de dimensions augmente permettent de pouvoirs séparer les données.


#### Liste des paramètres utilisés

- **type** = "C-classification"

- **kernel** = "linear"

- **cost** = 1

- **epsilon** = 0.1

- **shrinking** = TRUE

- **probability** = TRUE

#### Classification par classe SVM

Les classes sur l'axe des abscisses sont ordonnées en fonction de leur prévalence dans le jeu de donnée entier de manière descendante.

```{r, fig.width=15, fig.height=7, fig.cap="Figure 3: Classification par classe du modèle SVM pour n et p max calculé."}
plot_class(svm_Oldres[[length(svm_Oldres)]][["results"]][["pred_labs"]],
           svm_Oldres[[length(svm_Oldres)]][["results"]][["test_labs"]])
```


### XGBoost

- Language: R
- Package: xgboost

Le faible temps de calcul ainsi que la mauvaise accuracy de XGBoost est probablement dû au nombre d'itérations de boosting étant plutôt faible (nrounds = 6). Ce nombre d'itération est similaire au nombres epochs pour les réseaux de neurones.
 

On remarque que l'accuracy et particulièrement mauvaises pour les petites valeurs de n. Cela est dû au fait que similairement au réseau de neurones XGBoost utilise la décente de gradient. Or contrairement au modèle nn présenté ici la vitesse de la détente de gradient et fix. Cela présente un problème, car plus le nombre d'observation et petites plus la vitesse de la décente de gradient doit être élevé. Ceci se voit lors de l'entraînement du modèle ou la fonction de perte ne diminué pas pour des modèles avec un nombre d'observations faible.

Nous sommes toujours en train de nous renseigner sur le fonctionnement de XGBoost car ce modèle est particulièrement compliqué.

#### Liste des paramètres utilisés

- **nrounds** = 30

- **booster** = "gbtree"

- **eta** = 0.15

- **max_depth** = 13

- **subsample** = 1: Proportion of datapoints to use for training

- **lambda** = 3: L2 regularization

- **alpha** = 0: L1 regularization

- **objective** = "multi:softprob"

- **gamma** = 0

- **min_child_weight** = 0.1

- **colsample_bytree** = 0.1


#### Classification par classe XGBoost

Les classes sur l'axe des abscisses sont ordonnées en fonction de leur prévalence dans le jeu de donnée entier de manière descendante.

```{r, fig.width=15, fig.height=7, fig.cap="Figure 4: Classification par classe du modèle XGBoost pour n et p max calculé."}
plot_class(xgb_Oldres[[length(xgb_Oldres)]][["results"]][["pred_labs"]],
           xgb_Oldres[[length(xgb_Oldres)]][["results"]][["test_labs"]])
```


```{r, echo=TRUE}
# Supprimées où déplacer ce chunk pour lancer les autres scriptes a la compilation.
knitr::opts_chunk$set(eval = FALSE)
```


```{r, echo=TRUE}
source("Scripts/opti_all.R")
```


```{r, echo=TRUE}
source("Scripts/cv_all.R")
```


```{r, echo=TRUE}
source("Scripts/build_datasets.R")
```


# Organisation des fichiers et du code

- Les jeux de donnée originelle sont stockés dans le répertoire "OldData", et les données équilibrées sont stockées dans le répertoire "Data".

- Tous les scriptes ont une variable qui indique le nom du répertoire où se trouvent les données df_newas à utilisé dans la construction des modèles (ces répertoires et fichiers doivent déjà exister.)

- Tous les scriptes ont une ou plusieurs variables indiquant le nom du/des répertoire(s) dans lequel sera placer les résultats. Si ce/ces répertoire(s) n'existe pas déjà, il(s) sera/seront créé(s).

- Pour les machines à faible puissance de calcul, le scripte suivant s'exécute pour construire des sous-jeux de données test équivalent aux sous-jeux de donnée d'entraînement.

- Les résultats sont stockés par défaut dans les répertoires suivants:

    + Données original (69 classes) --> "OldDataOutput"
    
    + Données équilibrées (87 classes) --> "Output"
    
    + Données équilibrées (69 classes) --> "ReducedOutput"
    
    L'ensemble du travail est principalement réalisé repose sur 4 scriptes:

- Tous les scriptes contiennent des paramètres pour personnaliser la construction des modèles et les chemins d'enté et de sortie du script. Tous les scripts ont été construits de façon modulaire pour permettre l'exécution de chaque script de manière indépendante en ligne de commande avec un minimum de modifications.


L'ensemble du travail est principalement réalisé repose sur 4 scriptes:

- test_all_np.R: Teste tous les modèles en faisant varier le nombre d'observations et de variables.

- opti_all.R: Teste les modèles XGBoost et SVM sur l'ensemble des combinaisons des paramètres donnée.

- cv_all.R: Effectue une crosse la validation sur le jeu de donnée train et l'évalue sur les données test pour évaluer la stabilité des meilleurs paramètres.

- build_datasets.R: Construit les sous-jeux de données originale et équilibré et calcule les meilleures sondes. !!! Très gourment en ressources !!!



